{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b86184-f9ec-4b06-b2e6-85a2f70b9c0d",
   "metadata": {},
   "source": [
    "# Package and dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3cdfc1-bc84-48b0-9b34-4a4c58f1f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1aef150-2717-4c29-b89c-d242a1da6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "batch_size = 16\n",
    "train_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319e417-c309-4680-856e-642eae5d1299",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchaudio\n",
    "!pip install seaborn\n",
    "!pip install kaggle\n",
    "!pip install -U transformers\n",
    "!pip install datasets\n",
    "!pip install fsspec==2021.5.0\n",
    "!pip install jiwer==2.2.0\n",
    "!pip install pydub\n",
    "!pip install librosa\n",
    "!pip install bnunicodenormalizer\n",
    "!pip install pandarallel\n",
    "!pip install accelerate \n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76331f6-ab40-4dd5-9870-d2b4730ae326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl\n",
    "#! pip install git+https://github.com/huggingface/accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3815591a-3b14-4e70-9762-2725afc0157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unhash for collab only\n",
    "'''\n",
    "!mkdir /root/.kaggle\n",
    "\n",
    "\n",
    "import json\n",
    "dictionary ={\n",
    "\"username\":\"mushrafimunim\",\n",
    "\"key\":\"e5c337a189ee0a5c867ff83c21df4d2a\"\n",
    "}\n",
    "  \n",
    "json_object = json.dumps(dictionary, indent = 4)\n",
    "  \n",
    "with open(\"kaggle.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "\n",
    "%mv kaggle.json /root/.kaggle/kaggle.json\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf81016d-3f18-4174-9161-4c940c792c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from IPython import display as ipd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "#system files\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import zipfile\n",
    "import shutil\n",
    "import gc\n",
    "from pydub import AudioSegment\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "#transformers\n",
    "from transformers import AdamW,AutoTokenizer,AutoFeatureExtractor,AutoConfig,AutoModel,Wav2Vec2CTCTokenizer,Wav2Vec2ForCTC,Wav2Vec2Processor,Trainer,TrainingArguments,Wav2Vec2FeatureExtractor,get_linear_schedule_with_warmup,set_seed\n",
    "\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.functional as FT\n",
    "import torchaudio.transforms as TT\n",
    "\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, load_metric,Dataset,concatenate_datasets,set_caching_enabled, ClassLabel\n",
    "\n",
    "import librosa\n",
    "\n",
    "#normalization\n",
    "from pandarallel import pandarallel\n",
    "from bnunicodenormalizer import Normalizer \n",
    "pandarallel.initialize(progress_bar=True,nb_workers=8)\n",
    "tqdm.pandas()\n",
    "bnorm=Normalizer()\n",
    "\n",
    "# Set environment variables\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#accelerator\n",
    "from accelerate import Accelerator, DistributedType\n",
    "from datasets import load_dataset, load_metric \n",
    "import datasets\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e4540-7629-4e5f-8e94-7e955e3cba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unhash for collab only\n",
    "'''\n",
    "!kaggle competitions download -c dlsprint\n",
    "\n",
    "!unzip dlsprint.zip\n",
    "\n",
    "!rm -rf dlsprint.zip\n",
    "!git clone https://gitlab.com/mushrafi88/dlsprint.git\n",
    "!cp /content/dlsprint/vocab.json /content/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a94f5-d8b1-4b9b-afa2-843eeeb18943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_validation = pd.read_csv('validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0fd395-314a-4d65-a690-2e32f21f0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd train_files;for file in *.mp3;do l=$(echo -n \"$file,\"echo $(ffprobe $file 2>&1 | grep 'Duration' | cut -d',' -f1 | cut -d' ' -f4 | cut -d'.' -f1));echo \"$l\" >> train_files_duration.csv ;done\n",
    "#!sed -i '1s/^/path,duration\\n/' train_files_duration.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f6626-b440-4bb3-b0ba-170ce36a6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_files_duration = pd.read_csv('dlsprint/test_files_duration.csv')\n",
    "df_validation_files_duration = pd.read_csv('dlsprint/validation_files_duration.csv')\n",
    "df_train_files_duration = pd.read_csv('dlsprint/train_files_duration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4af98e-e855-4160-ae17-05dedff5a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_files_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b682a-7142-4ca0-82cb-f5657ce575c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619487be-7704-4268-83c0-aada7c13ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = df_train.sample(n=1)\n",
    "#df_validation = df_validation.sample(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8abe22-ec38-43a6-9789-d7c7851abc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0a4cce-a9f8-44f7-9ba1-5d8b154b048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a040e740-af5c-43ad-bd13-f46ed3468946",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14d780-d8a4-4fbb-8c94-1e115e940f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = pd.merge(df_train, df_validation, on=['path'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120680fc-1bd0-4382-ae2c-9cf8a92bf732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609d7b2-7ff7-4178-b458-6a7de11075d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!cd test_files && echo \"Test files\" && find . -maxdepth 1 -type f | sed 's/.*\\.//' | sort | uniq -c && # for file in *.mp3;do ffprobe -v error -select_streams a:0 -show_entries stream=duration -of default=noprint_wrappers=1:nokey=1 \"$file\";done|paste -sd+|bc -l\n",
    "!cd train_files && echo \"Train files\" &&find . -maxdepth 1 -type f | sed 's/.*\\.//' | sort | uniq -c\n",
    "!cd validation_files && echo \"Validation files\" && find . -maxdepth 1 -type f | sed 's/.*\\.//' | sort | uniq -c\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80754a45-a5d1-404c-a771-1564c702eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_unique_values(df):\n",
    "    df_empty = {}\n",
    "    for i in df.columns:\n",
    "        df_empty[i] = df[i].unique()\n",
    "    return df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b20ba-0dc8-49d6-92ba-0e81aafe2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(df):\n",
    "    a = df.isnull().sum()\n",
    "    a=a.tolist()\n",
    "    percent_missing = [ int(x)* 100 / len(df) for x in a]\n",
    "    error_per = pd.DataFrame({\n",
    "        'Columns':df.columns,         \n",
    "        'Total error': a,\n",
    "        'Error Percentage': percent_missing\n",
    "    })\n",
    "    print(tabulate(error_per, headers=['column','Total missing','% missing']))\n",
    "    sns.barplot(x='Columns',y='Error Percentage',data=error_per)\n",
    "    plt.ylabel('missing  %')\n",
    "    plt.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5074bef1-ca30-4ca0-a1bd-552c2f63487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45645cdd-6555-4709-9cf8-fbf7301a14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0c917-3b6f-4637-bfc8-ecffdd6ac284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_all_unique_values(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98e5d1-eb78-4e81-8969-f5c8e12e906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_all_unique_values(df_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7798ab4-ea66-4a4e-8fa6-08f83cb62239",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188810b4-57e2-44b0-8339-acdb4996046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors=[\"common_voice_bn_31727562\",\n",
    "        'common_voice_bn_30998934',\n",
    "        'common_voice_bn_31595526',\n",
    "        'common_voice_bn_31534853',\n",
    "        'common_voice_bn_31518061',\n",
    "        'common_voice_bn_31518373',\n",
    "        'common_voice_bn_31613621',\n",
    "        'common_voice_bn_31555333',\n",
    "        'common_voice_bn_31772113',\n",
    "        'common_voice_bn_31605391',\n",
    "        'common_voice_bn_31631175',\n",
    "        'common_voice_bn_31563901',\n",
    "        'common_voice_bn_31691690',\n",
    "        'common_voice_bn_31692010',\n",
    "        'common_voice_bn_31683653',\n",
    "        'common_voice_bn_31692182',\n",
    "        'common_voice_bn_31519976',\n",
    "        'common_voice_bn_31675793',\n",
    "        'common_voice_bn_31019914',\n",
    "        'common_voice_bn_31660287',\n",
    "        'common_voice_bn_31660384',\n",
    "        'common_voice_bn_31557261',\n",
    "        'common_voice_bn_31633101',\n",
    "        'common_voice_bn_31599243',\n",
    "        'common_voice_bn_31521515',\n",
    "        'common_voice_bn_31777802',\n",
    "        'common_voice_bn_31777848',\n",
    "        'common_voice_bn_31669646',\n",
    "        'common_voice_bn_31566083',\n",
    "        'common_voice_bn_31530331',\n",
    "        'common_voice_bn_31727697',\n",
    "        'common_voice_bn_31513270',\n",
    "        'common_voice_bn_31686295',\n",
    "        'common_voice_bn_31753693',\n",
    "        'common_voice_bn_31686334',\n",
    "        'common_voice_bn_31765546',\n",
    "        'common_voice_bn_31765548',\n",
    "        'common_voice_bn_31662742',\n",
    "        'common_voice_bn_31704856',\n",
    "        'common_voice_bn_31635344',\n",
    "        'common_voice_bn_31618327',\n",
    "        'common_voice_bn_31743074',\n",
    "        'common_voice_bn_31678862',\n",
    "        'common_voice_bn_31626674',\n",
    "        'common_voice_bn_31626677',\n",
    "        'common_voice_bn_31523889',\n",
    "        'common_voice_bn_31610804',\n",
    "        'common_voice_bn_31769538',\n",
    "        'common_voice_bn_31533273',\n",
    "        'common_voice_bn_31445621',\n",
    "        'common_voice_bn_31620650']\n",
    "errors = [i+'.mp3' for i in errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11538876-3234-4ac3-8078-5588dfb68cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_be_dropped_train = df_train[df_train['path'].isin(errors)].index\n",
    "index_to_be_dropped_validation = df_validation[df_validation['path'].isin(errors)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968519de-2b0b-4b9c-aa0b-672f48688504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_validation.drop(index_to_be_dropped_validation)\n",
    "df_train = df_train.drop(index_to_be_dropped_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16dfa3a-4520-424f-907e-6b5431e244b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561cffe-5afc-49ae-90a3-143e4cb77c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_unique_values(df_train)['up_votes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fa1e33-acbd-41fb-acc1-e96cb5a6fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_unique_values(df_train)['down_votes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b46f0-cc62-484c-899e-04a8303ad2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['down_votes'] == 0].sort_values(by=['down_votes'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ce672-049b-4915-9f4c-0f6b6f69469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_csv(df):\n",
    "    df['votes'] = df['up_votes'] - df['down_votes']\n",
    "    df['votes'] = df['votes'] + abs(df['votes'].min())\n",
    "    df.replace(0,df['votes'].mean(axis=0),inplace=True)\n",
    "    df['votes'] = df['votes']/df['votes'].max() \n",
    "    df = df.drop(['client_id','age','gender','accents','locale','up_votes','down_votes'],axis=1)\n",
    "    df = df.dropna(how='all')\n",
    "    if len(df) > 200000:\n",
    "        df['path'] = 'train_files/' + df['path']\n",
    "    if len(df) < 10000:\n",
    "        df['path'] = 'validation_files/' + df['path']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9824b1f-422e-4edf-9364-4b19a11f5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(my_str):\n",
    "    punctuations = '''```\u0012\u0010\u0002\b`\u0007\b£|¢|\u0007Ñ+-*/=EROero৳০১২৩৪৫৬৭৮৯012–34567•89।!()-[]{};:'\"“\\’…,<>.‚/?@#$%^&*_~‘—॥”‰🤣⚽️✌�￰৷￰'''\n",
    "    no_punct = \"\"\n",
    "    for char in my_str:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb6ad0-8491-45b5-916e-93a66421b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sen):\n",
    "    _words = [bnorm(word)['normalized']  for word in sen.split()]\n",
    "    return \" \".join([word for word in _words if word is not None]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add5386c-8153-4bcf-bc57-9704c65b1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = cleaning_csv(df_train)\n",
    "df_validation = cleaning_csv(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1524775-50a7-4bd0-94a4-e8c3b1d97c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sentence'] = df_train['sentence'].apply(lambda x : remove_punctuations(x))\n",
    "df_validation['sentence'] = df_validation['sentence'].apply(lambda x : remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa5120-c4fb-4a19-adc9-8fd5626c207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, df_validation], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44faae47-2003-474e-bdb9-759a34c56fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_train = df_train[df_train['sentence'].str.contains('V')]\n",
    "df_train = df_train.drop(to_drop_train.index)\n",
    "to_drop_train = df_train[df_train['sentence'].str.contains('A')]\n",
    "df_train = df_train.drop(to_drop_train.index)\n",
    "to_drop_train = df_train[df_train['sentence'].str.contains('B')]\n",
    "df_train = df_train.drop(to_drop_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e8e2c-80e5-45c2-be47-3a48be39e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"sentence\"]=df_train[\"sentence\"].parallel_apply(lambda x:normalize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93b1b8-11ad-44d3-b821-e60e0e8ffdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('dlsprint/df_sentence_normalized.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59a762-c327-4252-aa26-ca10e16f5b73",
   "metadata": {},
   "source": [
    "## checkpoint 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb95a2a2-802e-45df-a4c8-8e4c8be9b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dlsprint/df_sentence_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e5394-e9b1-46f1-9f7f-cf1d3d8f2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe35625-5d11-4bf3-93e9-a723568857f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Audio preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d546317-0816-4975-a49f-8ee4cb092161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_info_cleaning(df):\n",
    "    df['duration'] = df['duration'].str.replace(':','0')\n",
    "    df['duration'] = df['duration'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa26fd-bc70-471a-94f3-5ccaae019fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_files_duration = audio_info_cleaning(df_train_files_duration)\n",
    "df_train_files_duration['path'] = 'train_files/' + df_train_files_duration['path']\n",
    "\n",
    "df_validation_files_duration = audio_info_cleaning(df_validation_files_duration)\n",
    "df_validation_files_duration['path'] = 'validation_files/' + df_validation_files_duration['path']\n",
    "\n",
    "df_train_files_duration = pd.concat([df_train_files_duration, df_validation_files_duration], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265ce029-f5cf-4d22-8f32-8b5a4b99f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(df_train_files_duration,on='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32184c8-535b-441d-8939-0bf365dfe7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b5566-724b-41ad-a71a-20e72dd4967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_unique_values(df_train)['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007249ec-3fa9-4209-bba4-2542b7f34e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc546804-e698-4caf-9d3a-65ccb442c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav2vec2 works best for less than 5 s data\n",
    "# we can try lstm in this part for greater than 5s data\n",
    "\n",
    "df_train = df_train[(df_train['duration'] <= 5) & (df_train['duration'] >=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650327dc-ce2b-46f5-9aeb-5916dd775ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6fd84-6f30-4964-9025-8e515e860e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['votes','duration'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d82ff-ff77-458d-8e80-b2d65fa26afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('dlsprint/df_train_sen+duration.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6cfbf-52cd-4ef1-9c69-15ae2218b4f9",
   "metadata": {},
   "source": [
    "## checkpoint 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3014fbd1-84c5-4bc3-8e8a-36a6f71aba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dlsprint/df_train_sen+duration.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d63ac-4056-487d-bf03-c4580f1126ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mp3 to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e19b788-3ef3-4978-ab01-37ca7c18f788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_files/common_voice_bn_30991326.mp3</td>\n",
       "      <td>বাবা সত্যেন ঘোষ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_files/common_voice_bn_30991432.mp3</td>\n",
       "      <td>আপনি খুব একটা কথা বলার লোক নন তাই না</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_files/common_voice_bn_30991478.mp3</td>\n",
       "      <td>আপনি খুব একটা কথা বলার লোক নন তাই না</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_files/common_voice_bn_30991480.mp3</td>\n",
       "      <td>তার সাম্রাজ্য ছিল বিশ্বজুড়ে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_files/common_voice_bn_30991488.mp3</td>\n",
       "      <td>আক্রমণাত্মক ব্যাটিং ও দ্রুত রান সংগ্রাহক হিসেব...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107860</th>\n",
       "      <td>validation_files/common_voice_bn_31520874.mp3</td>\n",
       "      <td>ব্রিস্টল নতুন বিশ্ব অনুসন্ধানের যাত্রা শুরু কর...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107861</th>\n",
       "      <td>validation_files/common_voice_bn_31541319.mp3</td>\n",
       "      <td>পাণ্ডুর দুই স্ত্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107862</th>\n",
       "      <td>validation_files/common_voice_bn_31541568.mp3</td>\n",
       "      <td>তাকে ধরে ব্রিটিশ পুলিশ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107863</th>\n",
       "      <td>validation_files/common_voice_bn_30998752.mp3</td>\n",
       "      <td>তুমি ওকে ভালো করে বুঝিয়ে দিও</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107864</th>\n",
       "      <td>validation_files/common_voice_bn_30998756.mp3</td>\n",
       "      <td>তবে রোগাক্রান্ত পোষা বিড়ালের মাধ্যমে এটি বেশি ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107865 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path  \\\n",
       "0            train_files/common_voice_bn_30991326.mp3   \n",
       "1            train_files/common_voice_bn_30991432.mp3   \n",
       "2            train_files/common_voice_bn_30991478.mp3   \n",
       "3            train_files/common_voice_bn_30991480.mp3   \n",
       "4            train_files/common_voice_bn_30991488.mp3   \n",
       "...                                               ...   \n",
       "107860  validation_files/common_voice_bn_31520874.mp3   \n",
       "107861  validation_files/common_voice_bn_31541319.mp3   \n",
       "107862  validation_files/common_voice_bn_31541568.mp3   \n",
       "107863  validation_files/common_voice_bn_30998752.mp3   \n",
       "107864  validation_files/common_voice_bn_30998756.mp3   \n",
       "\n",
       "                                                 sentence  \n",
       "0                                         বাবা সত্যেন ঘোষ  \n",
       "1                    আপনি খুব একটা কথা বলার লোক নন তাই না  \n",
       "2                    আপনি খুব একটা কথা বলার লোক নন তাই না  \n",
       "3                             তার সাম্রাজ্য ছিল বিশ্বজুড়ে  \n",
       "4       আক্রমণাত্মক ব্যাটিং ও দ্রুত রান সংগ্রাহক হিসেব...  \n",
       "...                                                   ...  \n",
       "107860  ব্রিস্টল নতুন বিশ্ব অনুসন্ধানের যাত্রা শুরু কর...  \n",
       "107861                                 পাণ্ডুর দুই স্ত্রী  \n",
       "107862                             তাকে ধরে ব্রিটিশ পুলিশ  \n",
       "107863                       তুমি ওকে ভালো করে বুঝিয়ে দিও  \n",
       "107864  তবে রোগাক্রান্ত পোষা বিড়ালের মাধ্যমে এটি বেশি ...  \n",
       "\n",
       "[107865 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de190159-3cb1-4a69-af5c-050b40956b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset.from_pandas(df_train.sample(train_size))\n",
    "#submission = Dataset.from_pandas(df_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3879c3d6-facd-43e4-a4ec-ecda7a0abf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'sentence', '__index_level_0__'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba7693-0c20-4c58-8ff3-eeecdf4263b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hs * | grep \"dlsprint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3598a2c-d9c6-4320-b678-39bf891a55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.save_to_disk(\"dlsprint/train\")\n",
    "#submission.save_to_disk(\"dlsprint/submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b2ad2-5546-4bea-93d4-5c8526dcd044",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hs * | grep \"dlsprint\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2325cae-8872-4daa-8e67-18b9c0b01479",
   "metadata": {},
   "source": [
    "## checkpoint 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5b94b456-33f5-437a-804c-821c79c99280",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset.load_from_disk(\"dlsprint/train\")\n",
    "#submission = Dataset.load_from_disk(\"dlsprint/submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b780bd60-dbdf-4cc2-91ad-91bd8ccf6bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'sentence', '__index_level_0__'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8b844a-2f5b-48cb-8585-48b877e06da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ran_(df):\n",
    "    df['ra'] = df['path']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5253512f-edb8-4439-a419-b397ca5c60c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8ac179f83d410cab219ca01fb03dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = train.map(ran_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74a41eca-b107-4cb0-b13d-11c0d77ae159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e568ae-2658-4d01-821f-35a54d11f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895fd2d-3c27-41b0-837b-56c4706af89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_elements(train.remove_columns([\"path\"]), num_examples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d6748ff6-7e22-4532-aa51-da6fd7a26669",
   "metadata": {},
   "outputs": [],
   "source": [
    "resamplers = {  \n",
    "    48000: torchaudio.transforms.Resample(48000, 16000),\n",
    "    44100: torchaudio.transforms.Resample(44100, 16000),\n",
    "    32000: torchaudio.transforms.Resample(32000, 16000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9854f586-58f0-47df-b04b-8d56e749fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_torch(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resamplers[sampling_rate](speech_array).squeeze().numpy()\n",
    "    batch[\"speech\"] = np.trim_zeros(batch[\"speech\"])\n",
    "    batch[\"sampling_rate\"] = sampling_rate\n",
    "    batch[\"target_text\"] = batch[\"sentence\"]\n",
    "    return batch\n",
    "def speech_file_to_array_submission_torch(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resamplers[sampling_rate](speech_array).squeeze().numpy()\n",
    "    batch[\"speech\"] = np.trim_zeros(batch[\"speech\"])\n",
    "    batch[\"sampling_rate\"] = sampling_rate\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30fcb3fb-7e7e-4b12-9124-41ba50414b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afef80be-9cad-4713-a68f-54d16eb5f70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'sentence', '__index_level_0__'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c64dd7-6de2-4ef3-a762-acb0fb63961f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87d622a9-482a-493f-9068-800ea0df1152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984M\tdlsprint\n",
      "420K\tdlsprint-Copy1.ipynb\n",
      "420K\tdlsprint.ipynb\n",
      "540K\tdlsprint_mp3_torch_audio.ipynb\n",
      "56K\tdlsprint_xla_tpu.ipynb\n"
     ]
    }
   ],
   "source": [
    "!du -hs * | grep \"dlsprint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9c34bac8-f23b-4afd-b24c-60e1f5e3962a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1884d2f8699a4506806dddb863d4bd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = train.map(speech_file_to_array_torch, remove_columns=train.column_names,batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68abfc9-994a-433d-ad05-3618bb8bb524",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hs * | grep \"dlsprint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a54f48-2cb2-4342-8e4b-b38917d14c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None),\n",
       " 'sampling_rate': Value(dtype='int64', id=None),\n",
       " 'target_text': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8c461-725c-4a4b-9af5-643b3c9e4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.cleanup_cache_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3d6e3-0978-4219-9b6a-9099e9fe171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77489102-2699-4e91-a377-1be7c59e549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hs * | grep \"dlsprint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e7421968-d695-4c6d-9b1c-68265fe8b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_format(\"numpy\", columns=[\"speech\",\"sampling_rate\"], output_all_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa79292-0338-4f71-a98c-2dcf172ec2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d801fe1c-97c3-4daf-898c-326bc68e2bba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449d154-1818-43a9-b60d-c6cbb26539e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_for_token = pd.read_csv('dlsprint/df_sentence_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab9c4b-93a3-426c-8a82-b02825da41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(df):\n",
    "    all_text = \" \".join(df[\"sentence\"])\n",
    "    vocab = list(set(all_text))\n",
    "    vocab_dict = {v: k for k, v in enumerate(vocab)}\n",
    "    return vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c798cc5-c349-45ce-b805-7f100c396eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = extract_all_chars(df_all_for_token)\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87507da4-7954-47c2-a61c-d60baa6ae6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_dict_cleaner(vocab_dict):\n",
    "    del vocab_dict[' ']\n",
    "\n",
    "    vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "    vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "    print(len(vocab_dict))\n",
    "    return vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9655235-ce4c-481e-8b0a-a5a3760e05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = vocab_dict_cleaner(vocab_dict)\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91c901-8ffa-43e0-8bb4-208a1f04c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=[ '\\u200d',\n",
    "        ' ','!',\"'\",',','-','.',':',';','=','?','।',\n",
    "        'ঁ','ং','ঃ',\n",
    "        'অ','আ','ই','ঈ','উ','ঊ','ঋ','এ','ঐ','ও','ঔ',\n",
    "        'ক','খ','গ','ঘ','ঙ',\n",
    "        'চ','ছ','জ','ঝ','ঞ',\n",
    "        'ট','ঠ','ড','ঢ','ণ',\n",
    "        'ত','থ','দ','ধ','ন',\n",
    "        'প','ফ','ব','ভ','ম',\n",
    "        'য','র','ল',\n",
    "        'শ','ষ','স','হ',\n",
    "        'া','ি','ী','ু','ূ','ৃ','ে','ৈ','ো','ৌ','্',\n",
    "        'ৎ','ড়','ঢ়','য়',\n",
    "        '০','১','২','৩','৪','৫','৬','৭','৮','৯']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06815b0b-e600-4950-8d2d-a6de52a06dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict_munim = list(vocab_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3580c67-4a2f-4a83-a10a-ea17ffe60dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict_munim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a3ed45-612c-4a64-9cf4-c1d007bee77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "odertateaseamartatenai = [x for x in vocab if x not in vocab_dict_munim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393f923-fbbd-4c35-94da-65f5357a338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "odertateaseamartatenai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99eb7cf-fdc9-4b75-b433-cb12ccd6129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "amrtayase_odertay_nai = [x for x in vocab_dict_munim if x not in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce4f05-8311-46a5-9eb0-5e758f91984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "amrtayase_odertay_nai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535971ef-a827-46bc-bef8-6821157a7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d6943-8c35-40c8-bef0-015dc2ada242",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp vocab.json dlsprint/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "043f928e-c002-4229-8c97-6ddd589e73db",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "tokenizer_type = config.model_type if config.tokenizer_class is None else None\n",
    "config = config if config.tokenizer_class is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3729a29a-2871-4fb9-9aa0-bc67716b5c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  \"./\",\n",
    "  config=config,\n",
    "  tokenizer_type=tokenizer_type,\n",
    "  unk_token=\"[UNK]\",\n",
    "  pad_token=\"[PAD]\",\n",
    "  word_delimiter_token=\"।\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e2a77e4f-7408-4fb5-aaa6-9aa4ff4d2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c7115272-af90-4b38-81cf-5953686f828f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "263b8057-9263-4ead-9ed7-fb0de879ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d11aaa6d-f818-4bea-b0a9-a94c948a1080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: PreTrainedTokenizer(name_or_path='./', vocab_size=64, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]', 'additional_special_tokens': [AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True)]})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7880e389-dde2-4312-97cb-b09e0a671614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "430324d4-b742-4726-81f2-75641d028092",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_pretrained(\"model/wav2vec2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae047d2-f011-4d48-8584-c4a89268c4ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparing the inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf0fb45a-2a20-4e47-b8e6-28feb9307b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['speech', 'sampling_rate', 'target_text'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a13e82-9ac5-43ad-99f6-432bc30b7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train[0]['speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "896b1d19-98f8-44a0-93a6-638446dd9103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=16000).input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e20616fc-72a2-4ca7-8095-53052cd2d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_submission(batch):\n",
    "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=16000).input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b48c92-94af-49d3-9853-c4c0c3b26714",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ea238-4314-42d8-8de8-21f9048b216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "54d2ba41-a6a0-4d3d-afa7-98c83869f2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c847a815dc24c388bfd97059b4b08ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train=train.map(prepare_dataset, remove_columns=train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022dfdac-4363-4b79-94ad-a376584c6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hs * | grep \"dlsprint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0652de8-959d-43a3-bc0f-e8382b708243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.cleanup_cache_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb57a91b-5251-4ff7-8135-5775e4ea43b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47919a3-ba7b-41de-a6e3-77bbcb654a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hs * | grep \"dlsprint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c6a4402-9c54-4ef1-98cf-463626fc71d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['speech', 'sampling_rate', 'target_text', 'input_values', 'input_length', 'labels'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a65c519e-33e6-4ff4-88a8-46d3e184bf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech': array([ 7.3093590e-14, -2.1868138e-11,  7.7021632e-11, ...,\n",
       "         9.4649629e-05,  1.0731552e-04,  1.4034419e-04], dtype=float32),\n",
       " 'sampling_rate': 32000,\n",
       " 'input_values': array([-4.0990511e-05, -4.0990752e-05, -4.0989675e-05, ...,\n",
       "         9.8870834e-04,  1.1265014e-03,  1.4858220e-03], dtype=float32),\n",
       " 'input_length': 91480,\n",
       " 'labels': array([61, 11, 22, 23, 42, 11, 38, 23,  1, 49, 55, 58, 32, 45, 23, 38, 11,\n",
       "        45, 49, 16,  9, 22,  9, 33, 23, 21, 49, 58, 22, 11, 47, 50, 58, 49,\n",
       "        45, 22, 33, 32, 49, 15, 45, 32, 49, 21, 11, 20, 11, 61, 23, 61, 49,\n",
       "        35, 34, 29, 23, 14, 50, 49, 42, 23, 21, 50, 22, 50, 49, 54, 11, 28,\n",
       "        23, 61, 11, 33, 49, 45, 22, 50, 49, 28, 27, 32,  5, 32]),\n",
       " 'target_text': 'নির্দিষ্ট আপেক্ষিক গুরুত্ব পরিমাপ করতে একে বিভিন্ন সংখ্যা দ্বারা চিহ্নিত করা হয়েছে'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6b02c77-672f-474c-9348-376ed039eed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speech': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None),\n",
       " 'sampling_rate': Value(dtype='int64', id=None),\n",
       " 'target_text': Value(dtype='string', id=None),\n",
       " 'input_values': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None),\n",
       " 'input_length': Value(dtype='int64', id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3423c83-a780-4487-8b6d-587536e7b23e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb339ff9-3599-40d8-bb0a-34634ac72c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test=train.train_test_split(test_size=0.1, shuffle=True)\n",
    "train = train_test['train']\n",
    "test = train_test['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49459df4-d595-4022-bad5-501999f358e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3bfc3b-ff1a-44ee-8790-cfed0516eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9b24f8b-ad06-4c43-9b8b-a82fc6085acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.remove_columns(['speech','sampling_rate','target_text','input_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf93be29-44df-44a8-967e-03a91a7df070",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.remove_columns(['speech','sampling_rate','target_text','input_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3dbff-302a-4676-8618-fb47173ef123",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_int = random.randint(0, len(train)-1)\n",
    "print(\"Target text:\", train[rand_int][\"target_text\"])\n",
    "print(\"Input array shape:\",train[rand_int][\"speech\"].shape)\n",
    "print(\"Sampling rate:\", train[rand_int][\"sampling_rate\"])\n",
    "ipd.Audio(data=train['speech'][rand_int], autoplay=True, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a84015-bf3e-427e-817f-5ad1e793af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_int = random.randint(0, len(test)-1)\n",
    "print(\"Target text:\", test[rand_int][\"labels\"])\n",
    "#print(\"Input array shape:\", test[rand_int][\"input_values\"])\n",
    "ipd.Audio(data=test[rand_int][\"input_values\"], autoplay=True, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6e638-abb1-41a0-b6ef-ab49f9512d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0]['input_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "753fdc38-ebf3-49d6-990b-04bfb7813fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': array([-4.0990511e-05, -4.0990752e-05, -4.0989675e-05, ...,\n",
       "         9.8870834e-04,  1.1265014e-03,  1.4858220e-03], dtype=float32),\n",
       " 'labels': array([61, 11, 22, 23, 42, 11, 38, 23,  1, 49, 55, 58, 32, 45, 23, 38, 11,\n",
       "        45, 49, 16,  9, 22,  9, 33, 23, 21, 49, 58, 22, 11, 47, 50, 58, 49,\n",
       "        45, 22, 33, 32, 49, 15, 45, 32, 49, 21, 11, 20, 11, 61, 23, 61, 49,\n",
       "        35, 34, 29, 23, 14, 50, 49, 42, 23, 21, 50, 22, 50, 49, 54, 11, 28,\n",
       "        23, 61, 11, 33, 49, 45, 22, 50, 49, 28, 27, 32,  5, 32])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef17de0-81a2-4d68-9d6a-e5480620ac93",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54078871-15ef-4bfd-a486-d38eb6979c32",
   "metadata": {},
   "source": [
    "## Set up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63219294-b9c8-4206-beec-c8376e09fe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_values', 'labels'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e18fac8c-f0da-4771-9f62-832d14c10589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, df: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        input_features = [{\"input_values\": row[\"input_values\"]} for row in df]\n",
    "        label_features = [{\"input_ids\": row[\"labels\"]} for row in df]\n",
    "        \n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "899bdbc3-c855-4c95-84b4-8867287fbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5be99c3d-741b-4926-a0cc-4e4cea4d96f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_values': array([-0.00016368, -0.00016368, -0.00016368, ..., -0.00138846,\n",
      "       -0.00145205, -0.00079389], dtype=float32), 'labels': array([35, 32, 49, 35, 47, 27, 32, 49, 33, 11, 61, 11, 49, 45,  9, 47, 11,\n",
      "       44, 23, 44, 50, 49, 35, 32, 61, 50, 61, 11, 21, 50, 35, 32, 49, 45,\n",
      "       22, 23, 47, 22, 33, 49,  5, 11, 44, 32, 61])}\n"
     ]
    }
   ],
   "source": [
    "print([x for x in train_debug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df7d484c-5c6c-4638-9375-7cbc17642689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_values', 'labels'],\n",
      "    num_rows: 2\n",
      "})\n",
      "\n",
      "\n",
      "[{'input_values': array([-0.00016368, -0.00016368, -0.00016368, ..., -0.00138846,\n",
      "       -0.00145205, -0.00079389], dtype=float32), 'labels': array([35, 32, 49, 35, 47, 27, 32, 49, 33, 11, 61, 11, 49, 45,  9, 47, 11,\n",
      "       44, 23, 44, 50, 49, 35, 32, 61, 50, 61, 11, 21, 50, 35, 32, 49, 45,\n",
      "       22, 23, 47, 22, 33, 49,  5, 11, 44, 32, 61])}, {'input_values': array([-9.1227761e-05, -9.1230278e-05, -9.1220834e-05, ...,\n",
      "        4.1401412e-02,  4.2974263e-01,  1.0727605e+00], dtype=float32), 'labels': array([15, 45,  1, 11, 49, 44, 50, 17,  1, 49, 17, 61, 51, 22, 47, 32, 53,\n",
      "       61, 49, 48, 49, 39, 61, 23, 14,  1, 11, 49, 45, 50, 22, 32, 61, 23,\n",
      "        1, 49, 39, 23, 14, 50, 51, 32, 27, 50, 22, 23, 35])}]\n",
      "\n",
      "\n",
      "[{'input_values': array([-0.00016368, -0.00016368, -0.00016368, ..., -0.00138846,\n",
      "       -0.00145205, -0.00079389], dtype=float32)}, {'input_values': array([-9.1227761e-05, -9.1230278e-05, -9.1220834e-05, ...,\n",
      "        4.1401412e-02,  4.2974263e-01,  1.0727605e+00], dtype=float32)}]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "padded_data_=data_collator(train_debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b177a98b-9489-4f7d-9416-26399fe96876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_values', 'labels'],\n",
      "    num_rows: 2\n",
      "})\n",
      "\n",
      "\n",
      "[{'input_values': array([-0.00016368, -0.00016368, -0.00016368, ..., -0.00138846,\n",
      "       -0.00145205, -0.00079389], dtype=float32), 'labels': array([35, 32, 49, 35, 47, 27, 32, 49, 33, 11, 61, 11, 49, 45,  9, 47, 11,\n",
      "       44, 23, 44, 50, 49, 35, 32, 61, 50, 61, 11, 21, 50, 35, 32, 49, 45,\n",
      "       22, 23, 47, 22, 33, 49,  5, 11, 44, 32, 61])}, {'input_values': array([-9.1227761e-05, -9.1230278e-05, -9.1220834e-05, ...,\n",
      "        4.1401412e-02,  4.2974263e-01,  1.0727605e+00], dtype=float32), 'labels': array([15, 45,  1, 11, 49, 44, 50, 17,  1, 49, 17, 61, 51, 22, 47, 32, 53,\n",
      "       61, 49, 48, 49, 39, 61, 23, 14,  1, 11, 49, 45, 50, 22, 32, 61, 23,\n",
      "        1, 49, 39, 23, 14, 50, 51, 32, 27, 50, 22, 23, 35])}]\n",
      "\n",
      "\n",
      "[{'input_values': array([-0.00016368, -0.00016368, -0.00016368, ..., -0.00138846,\n",
      "       -0.00145205, -0.00079389], dtype=float32)}, {'input_values': array([-9.1227761e-05, -9.1230278e-05, -9.1220834e-05, ...,\n",
      "        4.1401412e-02,  4.2974263e-01,  1.0727605e+00], dtype=float32)}]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "padded_data_train=data_collator(train_debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3095a237-e7b3-4fe7-bb0e-8cbb4dc7edc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[-1.6368e-04, -1.6368e-04, -1.6368e-04,  ..., -1.3885e-03,\n",
       "         -1.4520e-03, -7.9389e-04],\n",
       "        [-9.1228e-05, -9.1230e-05, -9.1221e-05,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32), 'labels': tensor([[  35,   32,   49,   35,   47,   27,   32,   49,   33,   11,   61,   11,\n",
       "           49,   45,    9,   47,   11,   44,   23,   44,   50,   49,   35,   32,\n",
       "           61,   50,   61,   11,   21,   50,   35,   32,   49,   45,   22,   23,\n",
       "           47,   22,   33,   49,    5,   11,   44,   32,   61, -100, -100],\n",
       "        [  15,   45,    1,   11,   49,   44,   50,   17,    1,   49,   17,   61,\n",
       "           51,   22,   47,   32,   53,   61,   49,   48,   49,   39,   61,   23,\n",
       "           14,    1,   11,   49,   45,   50,   22,   32,   61,   23,    1,   49,\n",
       "           39,   23,   14,   50,   51,   32,   27,   50,   22,   23,   35]])}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00b53108-3e38-4715-b329-3a13126c645d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def padma(batch):\n",
    "    padded_data_train = data_collator(batch)\n",
    "    return padded_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b7930b6-ec9e-47c1-b1a2-2f5f014237eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 162])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data_train['labels'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c31c419-5b59-4346-b6ec-072a9e1b492e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 94996])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data_train['input_values'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3962831c-34ad-4938-aa59-906dede7729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data_test=data_collator(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a51676e-de2b-45af-9709-c65f7460b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_batch_size=8, eval_batch_size=8):\n",
    "    train_dataloader = DataLoader(\n",
    "        data_collator(train), shuffle=True, batch_size=train_batch_size\n",
    "    )\n",
    "    eval_dataloader = DataLoader(\n",
    "        data_collator(test), shuffle=False, batch_size=eval_batch_size\n",
    "    )\n",
    "    return train_dataloader, eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb828e9e-d34a-450a-93d6-d30463b0975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, eval_dataloader = create_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3444d4-2055-42b1-b52e-c1d5b250cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f4385e-5d80-4cc0-be64-60f21d06fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc48b8-8cea-4d7a-a8cf-df0cc9604b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa7299e-9609-4bb1-9cc0-c9765144f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6090a62-86b6-4454-98d3-a93ac63f3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCTC\n",
    "\n",
    "model = AutoModelForCTC.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4fb8f-3086-49e5-ba65-faa6cc3e7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7f1fd9-1566-45e7-b9e2-3917a8d4f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if hasattr(model, \"freeze_feature_extractor\"):\n",
    "#    model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae949f-16dc-4ed5-8ebb-723f2b6cb372",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"num_epochs\": 30,\n",
    "    \"train_batch_size\": 8, # Actual batch size will this x 8\n",
    "    \"eval_batch_size\": 32, # Actual batch size will this x 8\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22c758-efad-474a-90fa-3bbeafc68cc3",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55042d46-b4a9-47d1-8416-04177c9f1827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(model):\n",
    "    # Initialize accelerator\n",
    "    accelerator = Accelerator()\n",
    "\n",
    "    # To have only one message (and not 8) per logs of Transformers or Datasets, we set the logging verbosity\n",
    "    # to INFO for the main process only.\n",
    "    if accelerator.is_main_process:\n",
    "        datasets.utils.logging.set_verbosity_warning()\n",
    "        transformers.utils.logging.set_verbosity_info()\n",
    "    else:\n",
    "        datasets.utils.logging.set_verbosity_error()\n",
    "        transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "    train_dataloader, eval_dataloader = create_dataloaders(\n",
    "        train_batch_size=hyperparameters[\"train_batch_size\"], eval_batch_size=hyperparameters[\"eval_batch_size\"]\n",
    "    )\n",
    "    # The seed need to be set before we instantiate the model, as it will determine the random head.\n",
    "    set_seed(hyperparameters[\"seed\"])\n",
    "\n",
    "    # Instantiate optimizer\n",
    "    optimizer = AdamW(params=model.parameters(), lr=hyperparameters[\"learning_rate\"])\n",
    "\n",
    "    # Prepare everything\n",
    "    # There is no specific order to remember, we just need to unpack the objects in the same order we gave them to the\n",
    "    # prepare method.\n",
    "    model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, eval_dataloader\n",
    "    )\n",
    "\n",
    "    num_epochs = hyperparameters[\"num_epochs\"]\n",
    "    # Instantiate learning rate scheduler after preparing the training dataloader as the prepare method\n",
    "    # may change its length.\n",
    "    lr_scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=100,\n",
    "        num_training_steps=len(train_dataloader) * num_epochs,\n",
    "    )\n",
    "\n",
    "    # Instantiate a progress bar to keep track of training. Note that we only enable it on the main\n",
    "    # process to avoid having 8 progress bars.\n",
    "    progress_bar = tqdm(range(num_epochs * len(train_dataloader)), disable=not accelerator.is_main_process)\n",
    "    # Now we train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            accelerator.backward(loss)\n",
    "            \n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ebb7b7-018f-450b-82c8-9525bb4de323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import notebook_launcher\n",
    "\n",
    "notebook_launcher(training_function, (model,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8612cfd-be88-4ef0-ab0d-ec7f86922f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for collab only\n",
    "'''\n",
    "!cp -R /content/wav2vec2_bn /content/drive/MyDrive/buet_cse_fest_dlsprint\n",
    "from google.colab import drive\n",
    "drive.flush_and_unmount()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d6167-4230-4631-8c57-4a3a33a5aab7",
   "metadata": {},
   "source": [
    "# Testing and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffd832f-b723-41a8-93ee-2bfb7fe03bef",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff5654-6865-4a99-b87b-fb50901272fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
    "\n",
    "model = AutoModelForCTC.from_pretrained(\"wav2vec2_bn\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"wav2vec2_bn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b02b848-684e-4c73-a74c-80af17155878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame()\n",
    "df_submission['path'] = glob.glob(\"test_files/*.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c6fe72-4485-4578-a2c1-907148e33a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission = submission.map(speech_file_to_array_submission_torch, remove_columns=submission.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f1b4b8-b76c-4790-8fba-704892e55e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.set_format(\"numpy\", columns=[\"speech\",\"sampling_rate\"], output_all_columns=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
